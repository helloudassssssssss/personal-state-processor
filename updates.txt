Estoy probando nuevas funciones del openCV, el cual es una libereria opensources que ovy a estar usando para trackear el estaedo emocional en vivo de la cara de las personas.

Proceso de aprendizaje:
6/2/25
- img_vid_showcas.py basicamente es para mostrar imagenes y videos 

- rescale.py tiene dos funciones para reescalar cosas, uno para imagenes videos y live video, y otro para reescalar solo live video

- si cv.VideoCapture(0) osea que no especificas un path, va a autoamticamente usar la camar de la computeadora, si tenes otra camara podes especificar 1,2,3 dependiendo cuantas camaras tengas


7/2/25:
Hoy me concentre en aprender algunas funciones basicas de openCV, un par de tecnologias para deteccion de caras.

Funciones basicas:
- essential_functions.py: contiene funciones basicas muy importantes como hacer que una imagen, video, cam sea gris; 
  tmb blurear imagenes;
  ademas de eso tecnicas para manipular los bordes de las imagenes, edge cascade, dilating the image, eroding, resize image
  y finalmente cropear imagenes
- draw.py: contiene algunas funciones basicas sobre como dibujar formas geometricas y ademas tambien escribir sobre un canva, o imagen.

- No lo hice explicitamente, pero tmb podes transformar imagenes de otra forma, rotar, mover toda la imagen hacia un lado, resize image, flipear imagenes (espejo, vertical, horizontal), cropear imagenes.
- Edges y contours no son lo mismo matematicamente. 

2 tecnicas de deteccion de caras:
- fc_det_haar.py: que corresponde a face detection haar cascade technique, el cual en pocas palabras es peor que la 2da tecnica que presento abajo.

- fc_det_deep_learn_. . ..py (uno seteado para imagenes [_photo], otro para live video [_cam]): que corresponde Deep Learning-Based Face Detection (DNN), la cual es una tecnica mejor para detectar caras en todos los aspectos.

Diferencias entre ambos algoritmos para detectar caras:
- Haar cascade technique: usa patrones predefinidos (edges, textures) para clasificar si una imagen/live video, es una cara o no, osea que intenta matchear patrones memorizados que tiene, y los intenta matchear con lo que este viendo. 
    En power de procesamiento es buenisimo xq no consume casi nada, imaginate que la cpu me iba a 10-20% y con el programa corriendo y detectando mi cara, un 30% constante. 
    Pero si hablamos en detection de caras con angulos raros, algo que te tape, o ambiente oscuro, entonces le cuesta muchisimo mas, y es posible que no te detecte.

- Deep learning based face detection (DNN): usa una dataset masivo de caras para aprender rasgos faciales complejos, y se adapta a nuevas caras, porque aprende sobre el paso.
    Pero si hablamos de consumo de procesador, consume un monton, imaginate que la cpu me iba a 10-20% y con el programa corriendo y detectando mi cara, me va a 80-90%, y es un monton.
    Pero en cambio, es super preciso detectando caras


Detecion de expresiones faciales:
Deepface: es para face analysis, puede detectar emociones, edad, genero, tu raza etc... 
Esta mas optimizado que DNN.
Saca patrones de las caras de varios datasets gigantes,  y guarda estos patrones para usarlos en deteccion de caras.


[
  {
    'emotion': {'angry': 2.1, 'disgust': 0.5, 'fear': 3.2, 'happy': 87.6, 'neutral': 5.6, 'sad': 0.5, 'surprise': 0.5},
    'dominant_emotion': 'happy'
  }
]


8/2/25

- deepface_expressions_log.py logea todas las expresiones, conviertiendo las expresiones faciales de miedo en nuetro ya que hay muchos falsos negativos. Logea todo en un archivo csv, y eso lo voy a usar para la data visualizacion con el que experimente en el file de abajo

- expressions_visualization.ipynb: es un archivo jupyterlab, basicamente podes ejecutar cuadros de codigo por separado, y asi evitar tener que renderizar varios graficos en cadena, o leer el mismo dataframe varias veces antes de llegar a generar el grafico. 
  Jugue con dos tipos de graficos, line chart, el cual toma la cantidad de emociones que hubo en relacion al tiempo.
  Y tmb jugue con pie chart, el cual muestra cuantas expresiones de cada tipo hay. 


